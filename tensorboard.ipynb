{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d67b88ed-b8a8-4c2d-b986-cf9c1e744d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82d7f6d6-8972-48ac-a44a-6a24689257af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jay Ganesh\n"
     ]
    }
   ],
   "source": [
    "print(\"Jay Ganesh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e625915-1513-4850-8c9e-a3eada1dcd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "772d01f2-3c78-479f-a2d1-281703ef6f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "(xtrain,ytrain),(xtest,ytest)=keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c0b42b7-8900-4eb2-a77d-82e0940ca22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=xtrain/255\n",
    "xtest=xtest/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87c5a253-a09b-433a-8b1e-1c59562ad42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's first define a very simple Neural Network first, This can be achieved by Keras.Sequential and inside it\n",
    "#passing keras.layers.Dense(output,input,activation_function) Dense allows us to make the Neural Network dense\n",
    "model=keras.Sequential([keras.layers.Dense(10,input_shape=(784,),activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "496248e1-e76c-4f8b-b114-d22a52d5db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f59a3fc-d262-4ce8-96d2-b9faec800df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the xtrain we just displayed the image and using the ytrain we got to know about the actual output that is 5\n",
    "# Now we need to flatten our 2 dimensional array into one dimensional\n",
    "xtrainflatten=xtrain.reshape(len(xtrain),28*28) #first one is the no. of image and we don't want to edit but we just want to flatten the image pixel so in the \n",
    "#second argument we have passed 28*28 to reshape the 28 x 28 into 28*28 pixel i.e flatten it\n",
    "#Same implies on testing data so we will also do the same operation there\n",
    "xtestflatten=xtest.reshape(len(xtest),28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7e3503a-2671-4781-9486-cad99c4340f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - accuracy: 0.8762 - loss: 0.4721 \n",
      "Epoch 2/4\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9151 - loss: 0.3041  \n",
      "Epoch 3/4\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9205 - loss: 0.2837\n",
      "Epoch 4/4\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 14ms/step - accuracy: 0.9237 - loss: 0.2732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2231b5242b0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrainflatten,ytrain,epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6cb11d-bf08-45fa-8b18-13662d3ed25a",
   "metadata": {},
   "source": [
    "<h4>Above code is same as our Digit classification problem that we might be facing is that here for 4 epochs it was possible for us to understand and look at loss and accuracy but what is our epochs were suppose 2000 at this time it is very time consuming instead we can use TensorBoard for our problem. How it will be used we will check it below</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "419bc6bf-deb2-459a-b6fb-590300be5a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.8770 - loss: 0.4705\n",
      "Epoch 2/4\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9146 - loss: 0.3040\n",
      "Epoch 3/4\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9204 - loss: 0.2835\n",
      "Epoch 4/4\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9237 - loss: 0.2734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2230003c3b0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=keras.Sequential([keras.layers.Dense(10,input_shape=(784,),activation='sigmoid')])\n",
    "tb_callback=tf.keras.callbacks.TensorBoard(log_dir=\"logs/\",histogram_freq=1)\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(xtrainflatten,ytrain,epochs=4,callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb083b9-cfd9-4389-a830-74c210152143",
   "metadata": {},
   "source": [
    "<h4>What we did here is that we made a object for TensorBoard where the log_dir mentions the directory in which we have to store the file for the accuracy and loss for our model, hist_freq:  which controls the frequency (in epochs) at which the model's weights and biases are logged as histograms. </h4>\n",
    "<h5>We can check the graph and all using gitbash command prompt there you just need to go to your directory and write\n",
    "<h4>tensorboard --logdir logs/</h4><h5> to get the localhost address where your tensorboard would be working</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22af34d7-f0e2-4a5c-ab15-0358550c5657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 18632), started 2:19:54 ago. (Use '!kill 18632' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e3b9a340af55545d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e3b9a340af55545d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/train\n",
    "\n",
    "#The above line would also launch the tensorboard but the cmd thing is much good because you can view the thing in separate\n",
    "#Tab instead of inline like this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b27a7c1-46ee-412d-9f0d-f6c598b5d835",
   "metadata": {},
   "source": [
    "<h4>The above visualisation can also help us in comparing and understading different technique as in a single graph we can compare the peromrany of different scenario\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51381243-e14a-4e33-bcca-fa494b44bdfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
